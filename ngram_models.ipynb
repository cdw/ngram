{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from utils import get_tokenized_sentences\n",
    "from math import log, isclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2(x):\n",
    "    return log(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCounter:\n",
    "    def __init__(self, sentence_generator):\n",
    "        self.sentence_generator = sentence_generator\n",
    "        self.sentence_count = 0\n",
    "        self.token_count = 0\n",
    "        self.all_ngram_counts = {}\n",
    "        for ngram_length in range(1, 6):\n",
    "            self.all_ngram_counts[ngram_length] = {}\n",
    "        \n",
    "    def count(self):\n",
    "        for sentence in self.sentence_generator:\n",
    "            if sentence:\n",
    "                self.sentence_count += 1\n",
    "            for token in sentence:\n",
    "                self.token_count += 1\n",
    "            for ngram_length in range(1, 6):\n",
    "                ngram_counts = self.all_ngram_counts[ngram_length]\n",
    "                for i, sentence_ngram in enumerate(ngrams(sentence, ngram_length)):\n",
    "                    ngram_count = ngram_counts.setdefault(sentence_ngram, {'start': 0, 'all': 0})\n",
    "                    if i == 0:\n",
    "                        ngram_count['start'] += 1\n",
    "                    ngram_count['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainW_generator = get_tokenized_sentences('data/trainW_token_end.txt')\n",
    "trainW = WordCounter(trainW_generator)\n",
    "trainW.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainT_generator = get_tokenized_sentences('data/trainT_token_end.txt')\n",
    "trainT = WordCounter(trainT_generator)\n",
    "trainT.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_generator = get_tokenized_sentences('data/test1_token_end.txt')\n",
    "test1 = WordCounter(test1_generator)\n",
    "test1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_generator = get_tokenized_sentences('data/test2_token_end.txt')\n",
    "test2 = WordCounter(test2_generator)\n",
    "test2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_debug_generator = get_tokenized_sentences('data/train_debug_token_end.txt')\n",
    "train_debug = WordCounter(train_debug_generator)\n",
    "train_debug.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_debug_generator = get_tokenized_sentences('data/test_debug_token_end.txt')\n",
    "test_debug = WordCounter(test_debug_generator)\n",
    "test_debug.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ngram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramModel():\n",
    "    def __init__(self, train, k=1):\n",
    "        self.k = k\n",
    "        self.train_unigram_counts = train.all_ngram_counts[1].copy()\n",
    "        self.train_unigrams = set(self.train_unigram_counts.keys())\n",
    "        self.train_unigram_counts[('<UNK>',)] = {'all': 0, 'start': 0}\n",
    "        \n",
    "        self.train_prob_denom = train.token_count + len(self.train_unigram_counts) * self.k\n",
    "        self.train_prob_noms = {}\n",
    "        self.train_probs = {}\n",
    "        \n",
    "        for unigram, unigram_count in self.train_unigram_counts.items():\n",
    "            prob_nom = self.train_unigram_counts[unigram]['all'] + self.k\n",
    "            self.train_prob_noms[unigram] = prob_nom\n",
    "            self.train_probs[unigram] = prob_nom / self.train_prob_denom\n",
    "        assert isclose(sum(self.train_probs.values()), 1, rel_tol=1e-5)\n",
    "        \n",
    "    def calculate_avg_ll(self, test):\n",
    "        self.test_ll = 0\n",
    "        self.test_unigram_counts = test.all_ngram_counts[1].copy()\n",
    "        self.test_modified_unigram_counts = {}\n",
    "        self.test_unigram_lls = {}\n",
    "        \n",
    "        for unigram, unigram_count in self.test_unigram_counts.items():\n",
    "            if unigram not in self.train_unigrams:\n",
    "                unigram = (('<UNK>',))\n",
    "            unigram_ll = unigram_count['all'] * log2(self.train_probs[unigram])\n",
    "            self.test_ll += unigram_ll\n",
    "            self.test_modified_unigram_counts[unigram] = self.test_modified_unigram_counts.get(unigram, 0) + unigram_count['all']\n",
    "            self.test_unigram_lls[unigram] = self.test_unigram_lls.get(unigram, 0) + unigram_ll\n",
    "        \n",
    "        assert isclose(self.test_ll, sum(self.test_unigram_lls.values()), rel_tol=1)\n",
    "        assert sum(self.test_modified_unigram_counts.values()) == test.token_count\n",
    "        \n",
    "        self.avg_test_ll = self.test_ll / test.token_count\n",
    "        return self.avg_test_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.051738873949783"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_model_debug = UnigramModel(train_debug, k=1)\n",
    "unigram_model_debug.calculate_avg_ll(test_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.561905664153294"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_model_trainT = UnigramModel(trainT, k=1)\n",
    "unigram_model_trainT.calculate_avg_ll(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.497573151470494\n",
      "-18.555918913789192\n",
      "-18.54761854416354\n",
      "-18.54868310979827\n"
     ]
    }
   ],
   "source": [
    "unigram_model_trainW = UnigramModel(trainW, k=1)\n",
    "\n",
    "for text in [trainW, trainT, test1, test2]:\n",
    "    print(unigram_model_trainW.calculate_avg_ll(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.474849865464517\n",
      "-9.321327346878743\n",
      "-9.561905664153294\n",
      "-10.221738332232865\n"
     ]
    }
   ],
   "source": [
    "unigram_model_trainT = UnigramModel(trainT, k=1)\n",
    "\n",
    "for text in [trainW, trainT, test1, test2]:\n",
    "    print(unigram_model_trainT.calculate_avg_ll(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
